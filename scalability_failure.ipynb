{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d3d1287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Open shared_log.txt and look for lines containing both A and B, or broken lines.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "file_name = \"shared_log.txt\"\n",
    "\n",
    "def writer(tag):\n",
    "    # Low-level append (process-safe open), but NOT record-safe\n",
    "    fd = os.open(file_name, os.O_WRONLY | os.O_APPEND | os.O_CREAT)\n",
    "\n",
    "    for i in range(30):\n",
    "        os.write(fd, f\"{tag} Record {i}: \".encode())\n",
    "        time.sleep(0.005)\n",
    "        os.write(fd, b\"START | \")\n",
    "        time.sleep(0.005)\n",
    "        os.write(fd, b\"END\\n\")\n",
    "        time.sleep(0.001)\n",
    "\n",
    "    os.close(fd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # reset file\n",
    "    open(file_name, \"w\").close()\n",
    "\n",
    "    p1 = mp.Process(target=writer, args=(\"A\",))\n",
    "    p2 = mp.Process(target=writer, args=(\"B\",))\n",
    "\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "\n",
    "    print(\"Done. Open shared_log.txt and look for lines containing both A and B, or broken lines.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e0cd7",
   "metadata": {},
   "source": [
    "For Part 2, I simulated two different \"users/programs\" writing to the same log file at the same time. Each writer tries to save one record, but it writes the record in small pieces, with pauses in between. Because both writers are doing this at the same time, their pieces get mixed together in the file. That's why I see lines like A Record 0: B Record 0: START | START | END and also incomplete lines like A Record 1: END or a random START | END. As I increase the number of writes, the file gets more and more correupted because there are more chances for the writers to overlap. The file approach assumes records will stay together and only one writer will effectively write at the same time, but that assumption breaks once you have real concurrency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d962b",
   "metadata": {},
   "source": [
    "**Key question answer:** This design assumes you won't have multiple writers hitting the file at the same time, which isn't true when usage grows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
